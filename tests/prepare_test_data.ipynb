{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d78da37b",
   "metadata": {},
   "source": [
    "## Prepare test data across four domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fec7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All obtained from the MHH data using fetch_test_data.sql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "file_paths = [\n",
    "    Path(\"../data/mhh_condition.csv\"),\n",
    "    Path(\"../data/mhh_procedure.csv\"),\n",
    "    Path(\"../data/mhh_medication.csv\"),\n",
    "    Path(\"../data/mhh_measurement.csv\"),\n",
    "]\n",
    "\n",
    "for file_path in file_paths:\n",
    "    \n",
    "    print(f\"Processing {file_path.stem.split('_')[1]}\")\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Rename first column to keyword\n",
    "    df.rename(columns={df.columns[0]: \"keyword\", df.columns[1]: \"count\"}, inplace=True)\n",
    "    \n",
    "    df = df[df[\"keyword\"].notna()]\n",
    "    df = df[df[\"keyword\"].str.strip() != \"\"]\n",
    "\n",
    "    if file_path.stem.split('_')[1] == \"medication\":\n",
    "        df[\"omop_table\"] = \"drug_exposure\"\n",
    "        df[\"omop_field\"] = \"drug_concept_id\"\n",
    "    elif file_path.stem.split('_')[1] == \"condition\":\n",
    "        df[\"omop_table\"] = \"condition_occurrence\"\n",
    "        df[\"omop_field\"] = \"condition_concept_id\"\n",
    "    elif file_path.stem.split('_')[1] == \"procedure\":\n",
    "        df[\"omop_table\"] = \"procedure_occurrence\"\n",
    "        df[\"omop_field\"] = \"procedure_concept_id\"\n",
    "    elif file_path.stem.split('_')[1] == \"measurement\":\n",
    "        df[\"omop_table\"] = \"measurement\"\n",
    "        df[\"omop_field\"] = \"measurement_concept_id\"\n",
    "\n",
    "    # Eliminate the lowest 5% by count\n",
    "    lower_5pct_cutoff = df[\"count\"].quantile(0.05)\n",
    "    df = df[df[\"count\"] > lower_5pct_cutoff]\n",
    "\n",
    "    df = df.sort_values(\"count\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Now apply quartile sampling as before\n",
    "    total_samples = 200  # Total samples we want\n",
    "    sampled_list = []\n",
    "    \n",
    "    unique_counts = df[\"count\"].nunique()\n",
    "    df[\"quartile\"] = pd.qcut(df[\"count\"], q=4, labels=[\"Q4\", \"Q3\", \"Q2\", \"Q1\"], duplicates=\"drop\")\n",
    "    for q in [\"Q4\", \"Q3\", \"Q2\", \"Q1\"]:\n",
    "        quartile_data = df[df[\"quartile\"] == q]\n",
    "        sample_size = min(50, len(quartile_data))\n",
    "        if sample_size > 0:\n",
    "            sampled = quartile_data.sample(n=sample_size, random_state=42)\n",
    "            sampled_list.append(sampled)\n",
    "\n",
    "    sampled_list = [df.sample(n=min(total_samples, len(df)), random_state=42)]\n",
    "    result = pd.concat(sampled_list, ignore_index=True).sort_values(\"count\", ascending=False).reset_index(drop=True)\n",
    "    result.to_csv(f\"../data/evaluate/{file_path.stem.split('_')[1]}_mapping.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
